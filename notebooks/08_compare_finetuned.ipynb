{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- repo bootstrap ---------------------------------------------------------\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os, sys\n",
    "import subprocess, sys, importlib, os, re\n",
    "from datetime import datetime\n",
    "import truthbrush as tb\n",
    "\n",
    "def repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    while cur != cur.parent:\n",
    "        if (cur / \".env\").exists() or (cur / \".git\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    raise RuntimeError(\"repo root not found\")\n",
    "\n",
    "ROOT = repo_root(Path.cwd())\n",
    "load_dotenv(ROOT / \".env\")             # loads secrets\n",
    "sys.path.append(str(ROOT / \"src\"))     # optional helpers\n",
    "\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "OUT_DIR  = ROOT / \"outputs\"\n",
    "FIG_DIR  = OUT_DIR / \"figs\"; FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Repo root:\", ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED VERSION - Use the EXACT training prompt\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# THE EXACT SYSTEM PROMPT FROM TRAINING\n",
    "SYSTEM_PROMPT = \"\"\"You are analyzing Telegram posts about the Russia-Ukraine war. Return FOUR integers (E,B,P,C) with NO other text:\n",
    "\n",
    "E = Escalation (0-10): 0=humanitarian, 5=major weapons, 10=nuclear rhetoric\n",
    "B = Blame (-1/0/1): -1=neutral, 0=blames Ukraine/NATO, 1=blames Russia  \n",
    "P = Propaganda (0-3): 0=factual, 3=extreme/false\n",
    "C = Call-to-action (0/1): 0=none, 1=urges action\n",
    "\n",
    "Format: \"E,B,P,C\" (e.g. \"7,1,2,0\")\"\"\"\n",
    "\n",
    "# Your models\n",
    "FT_MODELS = {\n",
    "    \"mini\": \"ft:gpt-4o-mini-2024-07-18:politics-ai-research:ukraine-telegram-mini:BfSq29k1\",\n",
    "    \"nano\": \"ft:gpt-4.1-nano-2025-04-14:politics-ai-research:ukraine-classifier-nano:BfSlvv7Q\"\n",
    "    #\"full\": \"ft:gpt-4.1-2025-04-14:politics-ai-research:ukraine-classifier:BfStxtYw\"\n",
    "}\n",
    "\n",
    "# def classify_message(model_id, message_text):\n",
    "#     \"\"\"Classify using the EXACT training format\"\"\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model_id,\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "#             {\"role\": \"user\", \"content\": message_text}\n",
    "#         ],\n",
    "#         max_tokens=10,  # Only need 4 numbers + commas\n",
    "#         temperature=0    # CRITICAL for consistency\n",
    "#     )\n",
    "#     return response.choices[0].message.content.strip()\n",
    "\n",
    "# # Test messages\n",
    "# test_messages = [\n",
    "#     \"Putin announces new nuclear doctrine changes in response to Western arms shipments\",\n",
    "#     \"Red Cross delivers humanitarian aid to civilians in Mariupol\",\n",
    "#     \"NATO countries pledge additional military support package worth $5 billion\",\n",
    "#     \"BREAKING: Explosions reported across multiple Ukrainian cities, air raid sirens active\",\n",
    "#     \"Peace talks scheduled for next week in Geneva\"\n",
    "# ]\n",
    "\n",
    "# print(\"ðŸŽ¯ TESTING WITH CORRECT SYSTEM PROMPT\\n\")\n",
    "# print(\"Expected format: E,B,P,C (e.g., '7,1,2,0')\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# for model_name, model_id in FT_MODELS.items():\n",
    "#     print(f\"\\nðŸ“Š {model_name.upper()} Model:\")\n",
    "#     print(\"-\"*50)\n",
    "    \n",
    "#     for msg in test_messages:\n",
    "#         result = classify_message(model_id, msg)\n",
    "#         print(f\"Message: {msg[:60]}...\")\n",
    "#         print(f\"Result:  {result}\")\n",
    "        \n",
    "#         # Validate format\n",
    "#         if ',' in result and len(result.split(',')) == 4:\n",
    "#             try:\n",
    "#                 e, b, p, c = result.split(',')\n",
    "#                 e, b, p, c = int(e), int(b), int(p), int(c)\n",
    "#                 if 0 <= e <= 10 and -1 <= b <= 1 and 0 <= p <= 3 and 0 <= c <= 1:\n",
    "#                     print(\"âœ… Valid format!\")\n",
    "#                 else:\n",
    "#                     print(\"âš ï¸  Values out of range\")\n",
    "#             except:\n",
    "#                 print(\"âŒ Parse error\")\n",
    "#         else:\n",
    "#             print(\"âŒ Wrong format - not 4 comma-separated values\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Comprehensive Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import json\n",
    "\n",
    "# Setup\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    organization=\"org-d28nmVmBQpF2eNppsJOqaB9l\",\n",
    "    project=\"proj_SXBV23aZ3XH51x5y1qwF48jV\"\n",
    ")\n",
    "\n",
    "ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name != 'ukraine-final-project' else Path.cwd()\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are analyzing Telegram posts about the Russia-Ukraine war. Return FOUR integers (E,B,P,C) with NO other text:\n",
    "\n",
    "E = Escalation (0-10): 0=humanitarian, 5=major weapons, 10=nuclear rhetoric\n",
    "B = Blame (-1/0/1): -1=neutral, 0=blames Ukraine/NATO, 1=blames Russia  \n",
    "P = Propaganda (0-3): 0=factual, 3=extreme/false\n",
    "C = Call-to-action (0/1): 0=none, 1=urges action\n",
    "\n",
    "Format: \"E,B,P,C\" (e.g. \"7,1,2,0\")\"\"\"\n",
    "\n",
    "FT_MODELS = {\n",
    "    \"mini\": \"ft:gpt-4o-mini-2024-07-18:politics-ai-research:ukraine-telegram-mini:BfSq29k1\",\n",
    "    \"nano\": \"ft:gpt-4.1-nano-2025-04-14:politics-ai-research:ukraine-classifier-nano:BfSlvv7Q\",\n",
    "    \"full\": \"ft:gpt-4.1-2025-04-14:politics-ai-research:ukraine-classifier:BfStxtYw\"\n",
    "}\n",
    "\n",
    "def classify_message(model_id, message_text, max_retries=3):\n",
    "    \"\"\"Classify with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": message_text[:1000]}  # Truncate long messages\n",
    "                ],\n",
    "                max_tokens=10,\n",
    "                temperature=0\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                return None\n",
    "            time.sleep(1)\n",
    "    return None\n",
    "\n",
    "def parse_scores(score_str):\n",
    "    \"\"\"Parse E,B,P,C string into dict\"\"\"\n",
    "    try:\n",
    "        parts = score_str.split(',')\n",
    "        if len(parts) == 4:\n",
    "            return {\n",
    "                'E': int(parts[0]),\n",
    "                'B': int(parts[1]),\n",
    "                'P': int(parts[2]),\n",
    "                'C': int(parts[3])\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Disable httpx INFO logs\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "# Setup\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name != 'ukraine-final-project' else Path.cwd()\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are analyzing Telegram posts about the Russia-Ukraine war. Return FOUR integers (E,B,P,C) with NO other text:\n",
    "\n",
    "E = Escalation (0-10): 0=humanitarian, 5=major weapons, 10=nuclear rhetoric\n",
    "B = Blame (-1/0/1): -1=neutral, 0=blames Ukraine/NATO, 1=blames Russia  \n",
    "P = Propaganda (0-3): 0=factual, 3=extreme/false\n",
    "C = Call-to-action (0/1): 0=none, 1=urges action\n",
    "\n",
    "Format: \"E,B,P,C\" (e.g. \"7,1,2,0\")\"\"\"\n",
    "\n",
    "FT_MODELS = {\n",
    "    \"mini\": \"ft:gpt-4o-mini-2024-07-18:politics-ai-research:ukraine-telegram-mini:BfSq29k1\",\n",
    "    \"nano\": \"ft:gpt-4.1-nano-2025-04-14:politics-ai-research:ukraine-classifier-nano:BfSlvv7Q\",\n",
    "    \"full\": \"ft:gpt-4.1-2025-04-14:politics-ai-research:ukraine-classifier:BfStxtYw\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” DISCOVERING RATE LIMITS FOR EACH MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def test_rate_limits(model_id, model_name, test_duration=30):\n",
    "    \"\"\"Test rate limits by hammering the API for a short duration\"\"\"\n",
    "    print(f\"\\nTesting {model_name}...\")\n",
    "    \n",
    "    test_msg = \"Test message for rate limit discovery\"\n",
    "    successful_calls = 0\n",
    "    errors = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Track calls per second\n",
    "    call_times = []\n",
    "    \n",
    "    with tqdm(total=test_duration, desc=f\"{model_name} rate test\", unit=\"sec\") as pbar:\n",
    "        while time.time() - start_time < test_duration:\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model_id,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": test_msg}\n",
    "                    ],\n",
    "                    max_tokens=10,\n",
    "                    temperature=0\n",
    "                )\n",
    "                successful_calls += 1\n",
    "                call_times.append(time.time())\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                if \"rate limit\" in error_msg.lower():\n",
    "                    errors.append((\"rate_limit\", time.time(), error_msg))\n",
    "                    # Extract wait time if available\n",
    "                    import re\n",
    "                    wait_match = re.search(r'Please retry after (\\d+)s', error_msg)\n",
    "                    if wait_match:\n",
    "                        wait_time = int(wait_match.group(1))\n",
    "                        print(f\"\\n  âš ï¸ Rate limit hit! Wait time: {wait_time}s\")\n",
    "                        time.sleep(wait_time)\n",
    "                else:\n",
    "                    errors.append((\"other\", time.time(), error_msg))\n",
    "            \n",
    "            # Update progress\n",
    "            elapsed = time.time() - start_time\n",
    "            pbar.update(elapsed - pbar.n)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate calls per minute/second\n",
    "    if call_times:\n",
    "        # Calls per minute (last 60 seconds)\n",
    "        recent_calls = [t for t in call_times if t > time.time() - 60]\n",
    "        rpm = len(recent_calls)\n",
    "        \n",
    "        # Average time between calls\n",
    "        if len(call_times) > 1:\n",
    "            intervals = [call_times[i+1] - call_times[i] for i in range(len(call_times)-1)]\n",
    "            avg_interval = np.mean(intervals)\n",
    "            max_rps = 1 / avg_interval if avg_interval > 0 else float('inf')\n",
    "        else:\n",
    "            max_rps = successful_calls / total_time\n",
    "    else:\n",
    "        rpm = 0\n",
    "        max_rps = 0\n",
    "    \n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'successful_calls': successful_calls,\n",
    "        'total_errors': len(errors),\n",
    "        'rate_limit_errors': len([e for e in errors if e[0] == 'rate_limit']),\n",
    "        'calls_per_minute': rpm,\n",
    "        'max_calls_per_second': max_rps,\n",
    "        'avg_time_per_call': total_time / successful_calls if successful_calls > 0 else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  âœ… Results for {model_name}:\")\n",
    "    print(f\"     Successful calls: {successful_calls}\")\n",
    "    print(f\"     Rate limit errors: {results['rate_limit_errors']}\")\n",
    "    print(f\"     Estimated RPM: {results['calls_per_minute']:.0f}\")\n",
    "    print(f\"     Max RPS: {results['max_calls_per_second']:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test each model\n",
    "rate_limits = {}\n",
    "for model_name, model_id in FT_MODELS.items():\n",
    "    rate_limits[model_name] = test_rate_limits(model_id, model_name, test_duration=20)\n",
    "    time.sleep(2)  # Brief pause between models\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š RATE LIMIT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for model_name, limits in rate_limits.items():\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(f\"  Max RPM: ~{limits['calls_per_minute']:.0f}\")\n",
    "    print(f\"  Max RPS: ~{limits['max_calls_per_second']:.2f}\")\n",
    "    print(f\"  Safe parallel workers: {int(limits['max_calls_per_second'] * 0.8)}\")  # 80% of max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ TESTING PARALLEL THROUGHPUT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def test_parallel_rate(model_id, model_name, duration=20, parallel_workers=20):\n",
    "    \"\"\"Simple parallel test with verbose output\"\"\"\n",
    "    print(f\"\\nTesting {model_name} with {parallel_workers} parallel workers for {duration} seconds...\")\n",
    "    \n",
    "    # Tracking variables\n",
    "    successful_calls = 0\n",
    "    failed_calls = 0\n",
    "    call_times = []\n",
    "    errors = []\n",
    "    lock = threading.Lock()\n",
    "    stop_time = time.time() + duration\n",
    "    \n",
    "    def worker():\n",
    "        \"\"\"Worker function that continuously makes requests\"\"\"\n",
    "        worker_calls = 0\n",
    "        while time.time() < stop_time:\n",
    "            try:\n",
    "                start = time.time()\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model_id,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": \"Test escalation message\"}\n",
    "                    ],\n",
    "                    max_tokens=10,\n",
    "                    temperature=0\n",
    "                )\n",
    "                \n",
    "                with lock:\n",
    "                    nonlocal successful_calls\n",
    "                    successful_calls += 1\n",
    "                    call_times.append(time.time())\n",
    "                    worker_calls += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                with lock:\n",
    "                    nonlocal failed_calls\n",
    "                    failed_calls += 1\n",
    "                    if \"rate limit\" in str(e).lower():\n",
    "                        errors.append((\"rate_limit\", str(e)))\n",
    "                    else:\n",
    "                        errors.append((\"other\", str(e)))\n",
    "        \n",
    "        return worker_calls\n",
    "    \n",
    "    # Progress tracking\n",
    "    start_time = time.time()\n",
    "    last_print_time = start_time\n",
    "    last_print_calls = 0\n",
    "    \n",
    "    # Start workers\n",
    "    with ThreadPoolExecutor(max_workers=parallel_workers) as executor:\n",
    "        # Submit all workers\n",
    "        futures = [executor.submit(worker) for _ in range(parallel_workers)]\n",
    "        \n",
    "        # Monitor progress every second\n",
    "        while time.time() < stop_time:\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Print progress\n",
    "            elapsed = time.time() - start_time\n",
    "            current_calls = successful_calls\n",
    "            calls_this_second = current_calls - last_print_calls\n",
    "            overall_rps = current_calls / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            print(f\"  [{elapsed:>4.0f}s] Calls: {current_calls:>4} | \"\n",
    "                  f\"RPS (last sec): {calls_this_second:>3} | \"\n",
    "                  f\"RPS (avg): {overall_rps:>5.1f} | \"\n",
    "                  f\"Errors: {failed_calls}\")\n",
    "            \n",
    "            last_print_time = time.time()\n",
    "            last_print_calls = current_calls\n",
    "            \n",
    "            # Check for rate limit errors\n",
    "            rate_limit_errors = [e for e in errors if e[0] == \"rate_limit\"]\n",
    "            if len(rate_limit_errors) > 3:\n",
    "                print(f\"  âš ï¸ Multiple rate limit errors detected!\")\n",
    "        \n",
    "        # Wait for all workers to finish\n",
    "        worker_results = [f.result() for f in futures]\n",
    "    \n",
    "    # Final stats\n",
    "    total_duration = time.time() - start_time\n",
    "    final_rps = successful_calls / total_duration if total_duration > 0 else 0\n",
    "    \n",
    "    # Calculate sustained RPS (last 10 seconds)\n",
    "    recent_calls = [t for t in call_times if t > time.time() - 10]\n",
    "    sustained_rps = len(recent_calls) / min(10, total_duration) if recent_calls else 0\n",
    "    \n",
    "    print(f\"\\n  ðŸ“Š Final Results for {model_name}:\")\n",
    "    print(f\"     Total calls: {successful_calls}\")\n",
    "    print(f\"     Failed calls: {failed_calls}\")\n",
    "    print(f\"     Average RPS: {final_rps:.2f}\")\n",
    "    print(f\"     Sustained RPS (last 10s): {sustained_rps:.2f}\")\n",
    "    print(f\"     Rate limit errors: {len([e for e in errors if e[0] == 'rate_limit'])}\")\n",
    "    print(f\"     Calls per worker: {[r for r in worker_results]}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'workers': parallel_workers,\n",
    "        'successful_calls': successful_calls,\n",
    "        'failed_calls': failed_calls,\n",
    "        'avg_rps': final_rps,\n",
    "        'sustained_rps': sustained_rps,\n",
    "        'rate_limit_errors': len([e for e in errors if e[0] == \"rate_limit\"])\n",
    "    }\n",
    "\n",
    "# Test each model with different worker counts\n",
    "results = {}\n",
    "for model_name, model_id in FT_MODELS.items():\n",
    "    # Test with 5 workers first\n",
    "    results[model_name] = test_parallel_rate(model_id, model_name, duration=20, parallel_workers=20)\n",
    "    \n",
    "    # If no rate limit errors, try with more workers\n",
    "    if results[model_name]['rate_limit_errors'] == 0:\n",
    "        print(f\"\\n  ðŸ”„ No rate limits hit, testing with 50 workers...\")\n",
    "        results_10 = test_parallel_rate(model_id, model_name, duration=20, parallel_workers=30)\n",
    "        \n",
    "        # Use the better result\n",
    "        if results_10['avg_rps'] > results[model_name]['avg_rps']:\n",
    "            results[model_name] = results_10\n",
    "    \n",
    "    time.sleep(3)  # Pause between models\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š PARALLEL PROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(f\"  Best config: {result['workers']} workers\")\n",
    "    print(f\"  Throughput: {result['avg_rps']:.1f} calls/second\")\n",
    "    print(f\"  Can process 1K messages in: {1000/result['avg_rps']:.0f} seconds\")\n",
    "\n",
    "# Recommendation\n",
    "min_rps = min(r['avg_rps'] for r in results.values())\n",
    "recommended_workers = min(r['workers'] for r in results.values())\n",
    "\n",
    "print(f\"\\nðŸŽ¯ RECOMMENDATION FOR 174K MESSAGES:\")\n",
    "print(f\"  Use {recommended_workers} parallel workers (safe for all models)\")\n",
    "print(f\"  Expected throughput: {min_rps:.1f} messages/second\")\n",
    "print(f\"  Time for 174K messages: {174000/min_rps/60:.0f} minutes ({174000/min_rps/3600:.1f} hours)\")\n",
    "print(f\"  Cost estimate: ~${174000 * 0.00015:.2f} for GPT-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
