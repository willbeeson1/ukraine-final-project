{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- repo bootstrap ---------------------------------------------------------\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os, sys\n",
    "import subprocess, sys, importlib, os, re\n",
    "from datetime import datetime\n",
    "import truthbrush as tb\n",
    "\n",
    "def repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    while cur != cur.parent:\n",
    "        if (cur / \".env\").exists() or (cur / \".git\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    raise RuntimeError(\"repo root not found\")\n",
    "\n",
    "ROOT = repo_root(Path.cwd())\n",
    "load_dotenv(ROOT / \".env\")             # loads secrets\n",
    "sys.path.append(str(ROOT / \"src\"))     # optional helpers\n",
    "\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "OUT_DIR  = ROOT / \"outputs\"\n",
    "FIG_DIR  = OUT_DIR / \"figs\"; FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Repo root:\", ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────── UNIVERSAL PATCH CELL  (run once, very top of notebook) ──────────\n",
    "import subprocess, sys, importlib, os, types\n",
    "from pathlib import Path\n",
    "\n",
    "# 1️⃣  make sure both python-dotenv and curl_cffi exist\n",
    "def ensure(pkg, src=None):\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ModuleNotFoundError:\n",
    "        subprocess.check_call(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", src or pkg]\n",
    "        )\n",
    "\n",
    "ensure(\"python-dotenv\")\n",
    "ensure(\"curl_cffi\")\n",
    "\n",
    "# 2️⃣  reload .env (override=True guarantees fresh values)\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "\n",
    "# 3️⃣  import truthbrush and inject curl_cffi so NameError can’t happen\n",
    "import curl_cffi                     # noqa:  F401  (needed for side-effect)\n",
    "import truthbrush.api as tb_api\n",
    "tb_api.curl_cffi = curl_cffi         # hand it to truthbrush’s module scope\n",
    "\n",
    "import truthbrush as tb\n",
    "print(\"✔ Patch cell finished – environment refreshed, curl_cffi wired\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Score with Anthropic Model of Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║  SCORE Truth Social posts - Production Version                        ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "from pathlib import Path\n",
    "import json, time, pandas as pd, tqdm, re\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration - can change model\n",
    "ROOT = Path.cwd().resolve().parents[0]\n",
    "TRUTH_CSV = ROOT / \"outputs\" / \"truth_matches_merged.csv\"\n",
    "OUT_CSV = ROOT / \"outputs\" / \"truth_scores_anthropic_claude-opus-4-20250514.csv\"\n",
    "MODEL = \"claude-opus-4-20250514\"\n",
    "\n",
    "# Gold set\n",
    "GOLD_EX = \"\"\"\n",
    "```\n",
    "# Real-post EXEMPLARS (post → E,B,C):\n",
    "\n",
    "I never thought America could be talking nuclear war… our leaders’ rhetoric…                              → 10,0,0\n",
    "“World War III anyone?”                                                                                    → 10,-1,0\n",
    "FIRST COME THE TANKS, THEN COME THE NUKES. Get this crazy war ended, NOW.                                  → 5,-1,1\n",
    "Sharing Trump-peace article (Biden escalates war)                                                          → 0,0,0\n",
    "NATO condemns Putin for nuclear threats…                                                                   → 9,1,0\n",
    "Biden dragging us toward World War III—he must stop.                                                       → 10,0,1\n",
    "Call for GOP to use the 25th Amendment over Ukraine policy.                                                → 1,0,1\n",
    "Why won’t Europe pay its share for Ukraine defence?                                                        → 1,0,0\n",
    "Biden’s failures everywhere… same with Russia/Ukraine, maybe worse.                                        → 1,0,0\n",
    "VOTE FOR TRUMP – MAGA2024!                                                                                 → 1,0,1\n",
    "Russia threatens nukes; we have no negotiators—NO GOOD.                                                    → 9,1,0\n",
    "“Look at the missiles… NONE OF THIS HAPPENED WHILE I WAS PRESIDENT!”                                       → 7,0,0\n",
    "Just landed in Rome to help END this cruel and senseless war.                                              → 0,-1,0\n",
    "Trump statement: negotiations should begin immediately.                                                    → 0,-1,0\n",
    "Why give $40 B to Ukraine while Europe does so little?                                                     → 4,0,0\n",
    "Kherson village liberated—donate to 🇺🇦 aid funds today!                                                    → 2,1,1\n",
    "Avdeyevka update: fighting continues, no big changes.                                                      → 3,-1,0\n",
    "Biden wants talks with Xi & Putin re: possible WW III—he “doesn't remember quitting…”                      → 8,0,0\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt\n",
    "TRUTH_PROMPT = \"\"\"You are analyzing Truth Social posts about the Russia-Ukraine war.\n",
    "Score each post on THREE dimensions:\n",
    "1. Escalation (0-10): How militarily escalatory is the post?\n",
    "2. Blame (-1, 0, 1): Who does the post blame?\n",
    "   - 0 = Blames Ukraine/NATO/West\n",
    "   - 1 = Blames Russia/Putin\n",
    "   - -1 = No clear blame\n",
    "3. Call-to-Action (0, 1): Does it urge concrete action?\n",
    "   - 1 = Yes (vote, donate, stop funding, etc.)\n",
    "   - 0 = No explicit call\n",
    "\n",
    "Reference scale for escalation:\n",
    "0: Humanitarian/diplomatic content\n",
    "1: Peace negotiation focus\n",
    "2: Political warfare/disinformation\n",
    "3: Routine warfare casualties\n",
    "4: Major aid package discussions\n",
    "5: Major weapons systems\n",
    "6: Advanced weapons escalation\n",
    "7: Nation-wide strikes\n",
    "8: Strategic threats near borders\n",
    "9: Nuclear weapons threats\n",
    "10: Direct nuclear war rhetoric\n",
    "\n",
    "{GOLD_EX}\n",
    "\n",
    "CRITICAL: Respond ONLY with three integers in format E,B,C\n",
    "No spaces, no decimals, no words - just three numbers with two commas.\n",
    "Example: 5,0,1\"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(TRUTH_CSV, parse_dates=[\"created_at\"])\n",
    "print(f\"📊 Processing {len(df)} Truth Social posts\")\n",
    "\n",
    "# Initialize client\n",
    "client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# ── quiet the httpx + anthropic client ────────────────────────────────\n",
    "for name in (\"httpx\", \"anthropic\"):\n",
    "    logging.getLogger(name).setLevel(logging.WARNING)   # or logging.ERROR\n",
    "\n",
    "# FULL RUN - Comment out the next two lines for dry run\n",
    "# df = df.head(5).copy()\n",
    "# print(f\"🧪 DRY RUN WITH {len(df)} POSTS\")\n",
    "\n",
    "# Add index for tracking\n",
    "df[\"batch_idx\"] = range(len(df))\n",
    "\n",
    "# Prepare batch requests\n",
    "requests_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.isna(row.get(\"text\")) or str(row[\"text\"]).strip() == \"\":\n",
    "        continue\n",
    "        \n",
    "    request = {\n",
    "        \"custom_id\": str(row[\"batch_idx\"]),\n",
    "        \"params\": {\n",
    "            \"model\": MODEL,\n",
    "            \"max_tokens\": 25,  # Increased slightly for safety\n",
    "            \"temperature\": 0,\n",
    "            \"system\": TRUTH_PROMPT,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": str(row[\"text\"])[:1500]}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    requests_list.append(request)\n",
    "\n",
    "print(f\"📝 Prepared {len(requests_list)} requests\")\n",
    "\n",
    "# Create batch\n",
    "batch = client.messages.batches.create(requests=requests_list)\n",
    "print(f\"🚀 Launched batch {batch.id}\")\n",
    "\n",
    "# Monitor progress\n",
    "bar = tqdm.tqdm(total=len(requests_list), desc=\"Processing\", unit=\"req\")\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    batch_status = client.messages.batches.retrieve(batch.id)\n",
    "    completed = (batch_status.request_counts.succeeded + \n",
    "                batch_status.request_counts.errored + \n",
    "                batch_status.request_counts.canceled + \n",
    "                batch_status.request_counts.expired)\n",
    "    bar.n = completed\n",
    "    bar.refresh()\n",
    "    \n",
    "    if batch_status.processing_status == \"ended\":\n",
    "        bar.close()\n",
    "        break\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"✅ Batch processing complete in {elapsed_time/60:.1f} minutes\")\n",
    "\n",
    "# Parse results\n",
    "scores = {\"escalation\": {}, \"blame\": {}, \"cta\": {}}\n",
    "parse_errors = []\n",
    "\n",
    "# Retrieve the final batch status\n",
    "batch_final = client.messages.batches.retrieve(batch.id)\n",
    "\n",
    "if batch_final.results_url:\n",
    "    print(f\"📥 Fetching results from batch {batch.id}\")\n",
    "    \n",
    "    headers = {\n",
    "        \"x-api-key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "        \"anthropic-version\": \"2023-06-01\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(batch_final.results_url, headers=headers, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Process JSONL results line by line\n",
    "        for line in response.iter_lines():\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                result = json.loads(line)\n",
    "                custom_id = result.get(\"custom_id\")\n",
    "                \n",
    "                if custom_id is None:\n",
    "                    continue\n",
    "                \n",
    "                idx = int(custom_id)\n",
    "                \n",
    "                # Check if request succeeded\n",
    "                if result.get(\"result\", {}).get(\"type\") != \"succeeded\":\n",
    "                    parse_errors.append(f\"Request {custom_id} failed: {result.get('result', {}).get('type')}\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract the response text\n",
    "                message_content = result[\"result\"][\"message\"][\"content\"][0][\"text\"]\n",
    "                \n",
    "                # Parse the three integers - more flexible parsing\n",
    "                # Remove any whitespace and look for pattern like \"E,B,C\"\n",
    "                clean_content = message_content.strip()\n",
    "                match = re.match(r'^(\\d+),(-?\\d+),(\\d+)', clean_content)\n",
    "                \n",
    "                if match:\n",
    "                    e, b, c = int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "                    \n",
    "                    # Validate and store scores\n",
    "                    if 0 <= e <= 10: \n",
    "                        scores[\"escalation\"][idx] = e\n",
    "                    else:\n",
    "                        parse_errors.append(f\"Invalid escalation score {e} for request {custom_id}\")\n",
    "                        \n",
    "                    if b in (-1, 0, 1): \n",
    "                        scores[\"blame\"][idx] = b\n",
    "                    else:\n",
    "                        parse_errors.append(f\"Invalid blame score {b} for request {custom_id}\")\n",
    "                        \n",
    "                    if c in (0, 1): \n",
    "                        scores[\"cta\"][idx] = c\n",
    "                    else:\n",
    "                        parse_errors.append(f\"Invalid CTA score {c} for request {custom_id}\")\n",
    "                else:\n",
    "                    parse_errors.append(f\"Could not parse response for request {custom_id}: {message_content}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                parse_errors.append(f\"Error parsing result: {e}\")\n",
    "                continue\n",
    "                \n",
    "        print(f\"✅ Successfully parsed {len(scores['escalation'])} results\")\n",
    "    else:\n",
    "        print(f\"❌ Error fetching results: HTTP {response.status_code}\")\n",
    "else:\n",
    "    print(\"❌ No results URL available\")\n",
    "\n",
    "# Map scores back to dataframe\n",
    "df[\"escalation_score\"] = df[\"batch_idx\"].map(scores[\"escalation\"]).astype(\"Int64\")\n",
    "df[\"blame_direction\"] = df[\"batch_idx\"].map(scores[\"blame\"]).astype(\"Int64\")\n",
    "df[\"has_cta\"] = df[\"batch_idx\"].map(scores[\"cta\"]).astype(\"Int64\")\n",
    "\n",
    "# Save results\n",
    "df_out = df.drop(columns=[\"batch_idx\"])\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n✅ Scoring complete\")\n",
    "print(f\"   Total posts: {len(df)}\")\n",
    "print(f\"   Successfully scored: {len(scores['escalation'])}\")\n",
    "print(f\"   Failed: {len(df) - len(scores['escalation'])}\")\n",
    "print(f\"   Success rate: {len(scores['escalation'])/len(df)*100:.1f}%\")\n",
    "\n",
    "if parse_errors:\n",
    "    print(f\"\\n⚠️  Parse errors encountered ({len(parse_errors)} total):\")\n",
    "    for error in parse_errors[:5]:\n",
    "        print(f\"   - {error}\")\n",
    "    if len(parse_errors) > 5:\n",
    "        print(f\"   ... and {len(parse_errors) - 5} more errors\")\n",
    "\n",
    "# Show distribution of scores\n",
    "if len(scores['escalation']) > 0:\n",
    "    print(\"\\n📊 Score distributions:\")\n",
    "    esc_df = pd.Series(scores['escalation'].values())\n",
    "    print(f\"   Escalation: mean={esc_df.mean():.1f}, std={esc_df.std():.1f}, range={esc_df.min()}-{esc_df.max()}\")\n",
    "    \n",
    "    blame_df = pd.Series(scores['blame'].values())\n",
    "    blame_counts = blame_df.value_counts().sort_index()\n",
    "    print(f\"   Blame direction: {dict(blame_counts)}\")\n",
    "    \n",
    "    cta_df = pd.Series(scores['cta'].values())\n",
    "    print(f\"   Call-to-action: {cta_df.sum()} posts ({cta_df.mean()*100:.1f}%) have CTAs\")\n",
    "\n",
    "print(f\"\\n📁 Results saved to: {OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Score with OpenAI Model of Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║  SCORE Truth Social posts - OpenAI Batch API Version                  ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "from pathlib import Path\n",
    "import json, time, pandas as pd, re\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "ROOT = Path.cwd().resolve().parents[0]\n",
    "TRUTH_CSV = ROOT / \"outputs\" / \"truth_matches_merged.csv\"\n",
    "OUT_CSV = ROOT / \"outputs\" / \"truth_scores_openai_gpt-4o-mini.csv\"\n",
    "MODEL = \"gpt-4o-mini\"  # Options: gpt-4o-mini, gpt-4o, gpt-3.5-turbo\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ── Δ CODE: add right after you create the OpenAI client ────────────────\n",
    "RUBRIC_PATH = ROOT / \"prompt_files\" / \"truth_rubric.txt\"\n",
    "RUBRIC_PATH.write_text(SYSTEM_PROMPT)        # save the long prompt to disk\n",
    "\n",
    "rubric_file = client.files.create(\n",
    "    file=open(RUBRIC_PATH, \"rb\"),\n",
    "    purpose=\"assistants\"                     # file can be injected into messages\n",
    ")\n",
    "\n",
    "print(f\"✅ Rubric file uploaded: {rubric_file.id}\")\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(TRUTH_CSV)\n",
    "print(f\"📊 Processing {len(df)} Truth Social posts\")\n",
    "\n",
    "# Uncomment for dry run\n",
    "df = df.head(5).copy()\n",
    "print(f\"🧪 DRY RUN WITH {len(df)} POSTS\")\n",
    "\n",
    "# Add index for tracking\n",
    "df[\"batch_idx\"] = range(len(df))\n",
    "\n",
    "# Step 1: Create JSONL file with requests\n",
    "print(\"📝 Creating batch input file...\")\n",
    "batch_requests = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.isna(row.get(\"text\")) or str(row[\"text\"]).strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    system_prompt = (\n",
    "    \"You are a scoring assistant. \"\n",
    "    \"Consult the attached rubric and reply ONLY as E,B,C.\\n\\n\"\n",
    "    f\"<file:{rubric_file.id}>\"\n",
    "    )\n",
    "    \n",
    "    request = {\n",
    "        \"custom_id\": f\"request-{row['batch_idx']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": MODEL,\n",
    "            \"messages\": [\n",
    "                { \"role\": \"system\", \"content\": system_prompt },\n",
    "                { \"role\": \"user\",   \"content\": str(row['text'])[:1500] }\n",
    "            ],\n",
    "            \"max_tokens\": 10,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "    batch_requests.append(request)\n",
    "\n",
    "\n",
    "\n",
    "# Write JSONL file\n",
    "input_file_path = ROOT / \"outputs\" / \"openai_batch_input.jsonl\"\n",
    "with open(input_file_path, 'w') as f:\n",
    "    for request in batch_requests:\n",
    "        f.write(json.dumps(request) + '\\n')\n",
    "\n",
    "print(f\"✅ Created batch input file with {len(batch_requests)} requests\")\n",
    "\n",
    "# Step 2: Upload the file\n",
    "print(\"📤 Uploading batch file to OpenAI...\")\n",
    "with open(input_file_path, 'rb') as f:\n",
    "    batch_input_file = client.files.create(\n",
    "        file=f,\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "print(f\"✅ File uploaded: {batch_input_file.id}\")\n",
    "\n",
    "# Step 3: Create the batch\n",
    "print(\"🚀 Creating batch job...\")\n",
    "batch = client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"Truth Social Ukraine war posts scoring\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ Batch created: {batch.id}\")\n",
    "print(f\"   Status: {batch.status}\")\n",
    "\n",
    "# Step 4: Monitor the batch\n",
    "print(\"\\n⏳ Monitoring batch progress...\")\n",
    "start_time = time.time()\n",
    "\n",
    "while batch.status not in [\"completed\", \"failed\", \"expired\", \"cancelled\"]:\n",
    "    time.sleep(30)  # Check every 30 seconds\n",
    "    batch = client.batches.retrieve(batch.id)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    total = batch.request_counts.total\n",
    "    completed = batch.request_counts.completed\n",
    "    failed = batch.request_counts.failed\n",
    "    \n",
    "    if total > 0:\n",
    "        progress = (completed + failed) / total * 100\n",
    "        print(f\"   Progress: {progress:.1f}% ({completed} completed, {failed} failed) - {elapsed/60:.1f} minutes elapsed\")\n",
    "    else:\n",
    "        print(f\"   Status: {batch.status} - {elapsed/60:.1f} minutes elapsed\")\n",
    "\n",
    "print(f\"\\n✅ Batch {batch.status} in {(time.time() - start_time)/60:.1f} minutes\")\n",
    "\n",
    "# Step 5: Retrieve and parse results\n",
    "if batch.status == \"completed\" and batch.output_file_id:\n",
    "    print(\"📥 Downloading results...\")\n",
    "    \n",
    "    # Download the output file\n",
    "    output_file = client.files.content(batch.output_file_id)\n",
    "    output_file_path = ROOT / \"outputs\" / \"openai_batch_output.jsonl\"\n",
    "    \n",
    "    with open(output_file_path, 'wb') as f:\n",
    "        f.write(output_file.content)\n",
    "    \n",
    "    print(\"✅ Results downloaded\")\n",
    "    \n",
    "    # Parse results\n",
    "    scores = {\"escalation\": {}, \"blame\": {}, \"cta\": {}}\n",
    "    parse_errors = []\n",
    "    \n",
    "    with open(output_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                result = json.loads(line)\n",
    "                custom_id = result.get(\"custom_id\", \"\")\n",
    "                \n",
    "                # Extract index from custom_id (format: \"request-123\")\n",
    "                if custom_id.startswith(\"request-\"):\n",
    "                    idx = int(custom_id.split(\"-\")[1])\n",
    "                else:\n",
    "                    parse_errors.append(f\"Invalid custom_id format: {custom_id}\")\n",
    "                    continue\n",
    "                \n",
    "                # Check if request succeeded\n",
    "                if result.get(\"response\", {}).get(\"status_code\") != 200:\n",
    "                    parse_errors.append(f\"Request {custom_id} failed with status {result.get('response', {}).get('status_code')}\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract the response content\n",
    "                response_body = result[\"response\"][\"body\"]\n",
    "                choices = response_body.get(\"choices\", [])\n",
    "                \n",
    "                if not choices:\n",
    "                    parse_errors.append(f\"No choices in response for {custom_id}\")\n",
    "                    continue\n",
    "                \n",
    "                message_content = choices[0][\"message\"][\"content\"]\n",
    "                \n",
    "                # Parse the three integers\n",
    "                clean_content = message_content.strip()\n",
    "                match = re.match(r'^(\\d+),(-?\\d+),(\\d+)', clean_content)\n",
    "                \n",
    "                if match:\n",
    "                    e, b, c = int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "                    \n",
    "                    # Validate and store scores\n",
    "                    if 0 <= e <= 10:\n",
    "                        scores[\"escalation\"][idx] = e\n",
    "                    else:\n",
    "                        parse_errors.append(f\"Invalid escalation score {e} for {custom_id}\")\n",
    "                    \n",
    "                    if b in (-1, 0, 1):\n",
    "                        scores[\"blame\"][idx] = b\n",
    "                    else:\n",
    "                        parse_errors.append(f\"Invalid blame score {b} for {custom_id}\")\n",
    "                    \n",
    "                    if c in (0, 1):\n",
    "                        scores[\"cta\"][idx] = c\n",
    "                    else:\n",
    "                        parse_errors.append(f\"Invalid CTA score {c} for {custom_id}\")\n",
    "                else:\n",
    "                    parse_errors.append(f\"Could not parse response for {custom_id}: {message_content[:100]}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                parse_errors.append(f\"Error parsing result: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"✅ Successfully parsed {len(scores['escalation'])} results\")\n",
    "    \n",
    "    # Map scores back to dataframe\n",
    "    df[\"escalation_score\"] = df[\"batch_idx\"].map(scores[\"escalation\"]).astype(\"Int64\")\n",
    "    df[\"blame_direction\"] = df[\"batch_idx\"].map(scores[\"blame\"]).astype(\"Int64\")\n",
    "    df[\"has_cta\"] = df[\"batch_idx\"].map(scores[\"cta\"]).astype(\"Int64\")\n",
    "    \n",
    "    # Save results\n",
    "    df_out = df.drop(columns=[\"batch_idx\"])\n",
    "    df_out.to_csv(OUT_CSV, index=False)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n✅ Scoring complete\")\n",
    "    print(f\"   Total posts: {len(df)}\")\n",
    "    print(f\"   Successfully scored: {len(scores['escalation'])}\")\n",
    "    print(f\"   Failed: {len(df) - len(scores['escalation'])}\")\n",
    "    print(f\"   Success rate: {len(scores['escalation'])/len(df)*100:.1f}%\")\n",
    "    \n",
    "    if parse_errors:\n",
    "        print(f\"\\n⚠️  Parse errors encountered ({len(parse_errors)} total):\")\n",
    "        for error in parse_errors[:5]:\n",
    "            print(f\"   - {error}\")\n",
    "        if len(parse_errors) > 5:\n",
    "            print(f\"   ... and {len(parse_errors) - 5} more errors\")\n",
    "    \n",
    "    # Show distribution of scores\n",
    "    if len(scores['escalation']) > 0:\n",
    "        print(\"\\n📊 Score distributions:\")\n",
    "        esc_df = pd.Series(scores['escalation'].values())\n",
    "        print(f\"   Escalation: mean={esc_df.mean():.1f}, std={esc_df.std():.1f}, range={esc_df.min()}-{esc_df.max()}\")\n",
    "        \n",
    "        blame_df = pd.Series(scores['blame'].values())\n",
    "        blame_counts = blame_df.value_counts().sort_index()\n",
    "        print(f\"   Blame direction: {dict(blame_counts)}\")\n",
    "        \n",
    "        cta_df = pd.Series(scores['cta'].values())\n",
    "        print(f\"   Call-to-action: {cta_df.sum()} posts ({cta_df.mean()*100:.1f}%) have CTAs\")\n",
    "    \n",
    "    print(f\"\\n📁 Results saved to: {OUT_CSV}\")\n",
    "    \n",
    "    # Clean up temporary files (optional)\n",
    "    # input_file_path.unlink()\n",
    "    # output_file_path.unlink()\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Batch failed or no output file available\")\n",
    "    if hasattr(batch, 'errors') and batch.errors:\n",
    "        print(f\"   Errors: {batch.errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai batches list --limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = client.batches.retrieve(\"batch_683f2561d5908190932781bfec5b94b6\")\n",
    "print(bad.errors[0][\"message\"])      # shows 400: ‘content_block.type must be one of (“text”, “image_url”)’\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
